{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and validating data\n",
    "import emeval.input.spec_details as eisd\n",
    "import emeval.input.phone_view as eipv\n",
    "import emeval.input.eval_view as eiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers\n",
    "import emeval.viz.phone_view as ezpv\n",
    "import emeval.viz.eval_view as ezev\n",
    "import emeval.viz.geojson as ezgj\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics helpers\n",
    "import emeval.metrics.dist_calculations as emd\n",
    "import emeval.metrics.reference_trajectory as emr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For computation\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASTORE_URL = \"http://cardshark.cs.berkeley.edu\"\n",
    "AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\"\n",
    "sd_la = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"unimodal_trip_car_bike_mtv_la\")\n",
    "sd_sj = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"car_scooter_brex_san_jose\")\n",
    "sd_ucb = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"train_bus_ebike_mtv_ucb\")\n",
    "sd_ucb_reroute = eisd.SpecDetails(DATASTORE_URL, AUTHOR_EMAIL, \"train_bus_ebike_sm_reroute_mtv_ucb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_la = eipv.PhoneView(sd_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_sj = eipv.PhoneView(sd_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_ucb = eipv.PhoneView(sd_ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_ucb_reroute = eipv.PhoneView(sd_ucb_reroute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.analysed.phone_view as eapv\n",
    "importlib.reload(eapv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_la = eapv.create_analysed_view(pv_la, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "av_sj = eapv.create_analysed_view(pv_sj, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "av_ucb = eapv.create_analysed_view(pv_ucb, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "av_ucb_reroute = eapv.create_analysed_view(pv_ucb_reroute, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_la.map()[\"ios\"][\"ucb-sdb-ios-2\"][\"evaluation_ranges\"][0][\"evaluation_trip_ranges\"][1][\"evaluation_section_ranges\"][1][\"location_df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial-temporal error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_trajectory_input_tree(pv):\n",
    "    ref_tree = {}\n",
    "    \n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            for (r_idx, r) in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                if r[\"eval_role_base\"] != \"accuracy_control\":\n",
    "                    continue\n",
    "                for (tr_idx, tr) in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    for (sr_idx, sr) in enumerate(tr[\"evaluation_section_ranges\"]):\n",
    "                        # This is a Shapely LineString\n",
    "                        section_gt_leg = pv.spec_details.get_ground_truth_for_leg(tr[\"trip_id_base\"], sr[\"trip_id_base\"])\n",
    "                        section_gt_shapes = gpd.GeoSeries(eisd.SpecDetails.get_shapes_for_leg(section_gt_leg))\n",
    "                        if len(section_gt_shapes) == 1:\n",
    "                            print(\"No ground truth route for %s %s, must be polygon, skipping...\" % (tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "                            assert section_gt_leg[\"type\"] != \"TRAVEL\", \"For %s, %s, %s, %s, %s found type %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx, section_gt_leg[\"type\"])\n",
    "                            continue\n",
    "                        print(\"For travel leg %s, %s, %s, %s, %s, checking location_df of length = %s\" % \n",
    "                              (phone_os, phone_label, r[\"eval_role_base\"], tr[\"trip_id_base\"], sr[\"trip_id_base\"], len(sr[\"location_df\"])))\n",
    "                        if len(sr['location_df']) == 0:\n",
    "                            print(\"No sensed locations found, role = %s skipping...\" % (r[\"eval_role_base\"]))\n",
    "                            # assert r[\"eval_role_base\"] == \"power_control\", \"Found no locations for %s, %s, %s, %s, %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx)\n",
    "                            continue\n",
    "                            \n",
    "                        print(\"Processing travel leg %s, %s, %s, %s, %s\" %\n",
    "                              (phone_os, phone_label, r[\"eval_role_base\"], tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "                        sec_name = tr[\"trip_id_base\"] + \"/\" + sr[\"trip_id_base\"] + \"_\" + str(r_idx)\n",
    "                        if sec_name not in ref_tree:\n",
    "                            ref_tree[sec_name] = {\n",
    "                                \"trip_id\": tr[\"trip_id_base\"],\n",
    "                                \"section_id\": sr[\"trip_id_base\"],\n",
    "                                \"run\": r_idx,\n",
    "                                \"ground_truth\": {\n",
    "                                    \"leg\": section_gt_leg\n",
    "                                }\n",
    "                            }\n",
    "                        \n",
    "                        assert sec_name in ref_tree\n",
    "                        e = ref_tree[sec_name]\n",
    "                        # This is a GeoDataFrame\n",
    "                        # section_measured_points = get_travel_trajectory(sr['location_df'], polygons)\n",
    "                        section_measured_points = sr[\"location_df\"]\n",
    "                        if \"temporal_control\" not in e:\n",
    "                            e[\"temporal_control\"] = {}\n",
    "                            e[\"start_ts\"] = sr[\"start_ts\"]\n",
    "                            e[\"end_ts\"] = sr[\"end_ts\"]\n",
    "                        e[\"temporal_control\"][phone_os] = sr\n",
    "    return ref_tree\n",
    "\n",
    "def fill_ref_tree_entry(pv, e):\n",
    "    print(\"Considering entry %s %s %s\" % (e[\"trip_id\"], e[\"section_id\"], e[\"run\"]))\n",
    "    curr_tz = pv.spec_details.eval_tz\n",
    "    assert \"android\" in e[\"temporal_control\"] and \"ios\" in e[\"temporal_control\"]\n",
    "    (e[\"reference_algo\"], e[\"reference_df\"]) = emr.final_ref_ensemble(e, 25, tz=curr_tz)\n",
    "\n",
    "def get_reference_trajectory_tree(pv, ref_tree_root):\n",
    "    curr_ref_tree = get_reference_trajectory_input_tree(pv)\n",
    "    ref_tree_root[pv.spec_details.CURR_SPEC_ID] = curr_ref_tree\n",
    "    [fill_ref_tree_entry(pv, e) for e in curr_ref_tree.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We still construct reference trajectories from the raw data\n",
    "# Evaluation trajectories are from the analysed data\n",
    "ref_tree = {}\n",
    "get_reference_trajectory_tree(pv_la, ref_tree)\n",
    "get_reference_trajectory_tree(pv_sj, ref_tree)\n",
    "get_reference_trajectory_tree(pv_ucb, ref_tree)\n",
    "get_reference_trajectory_tree(pv_ucb_reroute, ref_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatio_temporal_errors(pv):\n",
    "    spatial_error_df = pd.DataFrame()\n",
    "    \n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            for (r_idx, r) in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                run_errors = []\n",
    "                for (tr_idx, tr) in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    trip_errors = []\n",
    "                    for (sr_idx, sr) in enumerate(tr[\"evaluation_section_ranges\"]):\n",
    "                        # This is a Shapely LineString\n",
    "                        section_gt_leg = pv.spec_details.get_ground_truth_for_leg(tr[\"trip_id_base\"], sr[\"trip_id_base\"])\n",
    "                        section_gt_shapes = gpd.GeoSeries(eisd.SpecDetails.get_shapes_for_leg(section_gt_leg))\n",
    "                        if len(section_gt_shapes) == 1:\n",
    "                            print(\"No ground truth route for %s %s, must be polygon, skipping...\" % (tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "                            assert section_gt_leg[\"type\"] != \"TRAVEL\", \"For %s, %s, %s, %s, %s found type %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx, section_gt_leg[\"type\"])\n",
    "                            continue\n",
    "                        if len(sr['location_df']) < 2:\n",
    "                            print(\"Too few sensed locations found, role = %s skipping...\" % (r[\"eval_role_base\"]))\n",
    "                            # assert r[\"eval_role_base\"] == \"power_control\", \"Found no locations for %s, %s, %s, %s, %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx)\n",
    "                            continue\n",
    "                            \n",
    "                        print(\"Processing travel leg %s, %s, %s, %s, %s\" %\n",
    "                              (phone_os, phone_label, r[\"eval_role_base\"], tr[\"trip_id_base\"], sr[\"trip_id_base\"]))\n",
    "\n",
    "                        # This is a GeoDataFrame\n",
    "                        section_geo_df = emd.to_geo_df(sr[\"location_df\"])\n",
    "                        filtered_section_geo_df = emd.filter_geo_df(section_geo_df, section_gt_shapes)\n",
    "                        if len(filtered_section_geo_df) < 2:\n",
    "                            print(\"Too few filtered locations found, role = %s skipping...\" % (r[\"eval_role_base\"]))\n",
    "                            # assert r[\"eval_role_base\"] == \"power_control\", \"Found no locations for %s, %s, %s, %s, %s\" % (phone_os, phone_label, r_idx, tr_idx, sr_idx)\n",
    "                            continue\n",
    "\n",
    "                        \n",
    "                        # This is a GeoDataFrame\n",
    "                        eval_df = emr.get_int_aligned_trajectory(filtered_section_geo_df, tz=pv.spec_details.eval_tz)\n",
    "                        sr[\"resampled_df\"] = eval_df\n",
    "                        spec_name = tr[\"trip_id_base\"]+\"/\"+sr[\"trip_id_base\"]+\"_\"+str(r_idx)\n",
    "                        reference_df = ref_tree[pv.spec_details.CURR_SPEC_ID][spec_name][\"reference_df\"]\n",
    "\n",
    "                        # Match these up by timestamp\n",
    "                        merged_df = pd.merge(eval_df, reference_df, on=\"ts\", how=\"inner\", suffixes=(\"_e\", \"_r\")).sort_values(by=\"ts\", axis=\"index\")\n",
    "                        print(\"len(eval_df) = %d, len(reference_df) = %d len(merged_df) = %d\" % (len(eval_df), len(reference_df), len(merged_df)))\n",
    "                        merged_df[\"t_distance\"] = emd.to_utm_series(gpd.GeoSeries(merged_df.geometry_e)).distance(emd.to_utm_series(gpd.GeoSeries(merged_df.geometry_r)))\n",
    "                        ne = len(merged_df)\n",
    "                        curr_spatial_error_df = gpd.GeoDataFrame({\"error\": merged_df[\"t_distance\"],\n",
    "                            \"ts\": merged_df.ts, \"geometry\": merged_df.geometry_e,\n",
    "                             \"phone_os\": np.repeat(phone_os, ne),\n",
    "                             \"phone_label\": np.repeat(phone_label, ne),\n",
    "                             \"role\": np.repeat(r[\"eval_role_base\"], ne),\n",
    "                             \"timeline\": np.repeat(pv.spec_details.CURR_SPEC_ID, ne), \n",
    "                              \"run\": np.repeat(r_idx, ne),\n",
    "                              \"trip_id\": np.repeat(tr[\"trip_id_base\"], ne),\n",
    "                              \"section_id\": np.repeat(sr[\"trip_id_base\"], ne)\n",
    "                        })\n",
    "                        spatial_error_df = pd.concat([spatial_error_df, curr_spatial_error_df], axis=\"index\")\n",
    "    return spatial_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df = pd.DataFrame()\n",
    "st_errors_df = pd.concat([st_errors_df, get_spatio_temporal_errors(av_la)], axis=\"index\")\n",
    "st_errors_df = pd.concat([st_errors_df, get_spatio_temporal_errors(av_sj)], axis=\"index\")\n",
    "st_errors_df = pd.concat([st_errors_df, get_spatio_temporal_errors(av_ucb)], axis=\"index\")\n",
    "st_errors_df = pd.concat([st_errors_df, get_spatio_temporal_errors(av_ucb_reroute)], axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge the reroutes\n",
    "st_errors_df.timeline.replace(\"train_bus_ebike_sm_reroute_mtv_ucb\", \"train_bus_ebike_mtv_ucb\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2q_map = {\"power_control\": 0, \"HAMFDC\": 1, \"MAHFDC\": 2, \"HAHFDC\": 3, \"accuracy_control\": 4}\n",
    "q2r_map = {0: \"power\", 1: \"HAMFDC\", 2: \"MAHFDC\", 3: \"HAHFDC\", 4: \"accuracy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df[\"quality\"] = st_errors_df.role.apply(lambda r: r2q_map[r])\n",
    "st_errors_df[\"label\"] = st_errors_df.role.apply(lambda r: r.replace('_control', ''))\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\", \"car_scooter_brex_san_jose\", \"unimodal_trip_car_bike_mtv_la\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query('timeline == \"train_bus_ebike_mtv_ucb\" & run == 0 & phone_os == \"android\" & quality == 0').error.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference dataset choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatio_algo(pv):\n",
    "    spatial_algo_list = []\n",
    "    \n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            for (r_idx, r) in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                run_errors = []\n",
    "                for (tr_idx, tr) in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    trip_errors = []\n",
    "                    for (sr_idx, sr) in enumerate(tr[\"evaluation_section_ranges\"]):\n",
    "                        spec_name = tr[\"trip_id_base\"]+\"/\"+sr[\"trip_id_base\"]+\"_\"+str(r_idx)\n",
    "                        if spec_name not in ref_tree[pv.spec_details.CURR_SPEC_ID]:\n",
    "                            print(\"No reference dataset for %s, skipping\" % spec_name)\n",
    "                            continue\n",
    "                        e = ref_tree[pv.spec_details.CURR_SPEC_ID][spec_name]\n",
    "                        curr_ref_algo = {\"algo\": e[\"reference_algo\"],\n",
    "                             \"phone_os\": phone_os,\n",
    "                             \"phone_label\": phone_label,\n",
    "                             \"role\": r[\"eval_role_base\"],\n",
    "                             \"timeline\": pv.spec_details.CURR_SPEC_ID, \n",
    "                              \"run\": r_idx,\n",
    "                              \"trip_id\": tr[\"trip_id_base\"],\n",
    "                              \"section_id\": sr[\"trip_id_base\"]}\n",
    "                        spatial_algo_list.append(curr_ref_algo)\n",
    "    return spatial_algo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_algo_list = []\n",
    "spatial_algo_list.extend(get_spatio_algo(pv_la))\n",
    "spatial_algo_list.extend(get_spatio_algo(pv_sj))\n",
    "spatial_algo_list.extend(get_spatio_algo(pv_ucb))\n",
    "spatial_algo_df = pd.DataFrame(spatial_algo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_set = set(spatial_algo_df[spatial_algo_df.algo == \"ct\"].section_id.unique())\n",
    "tf_set = set(spatial_algo_df[spatial_algo_df.algo == \"tf\"].section_id.unique())\n",
    "print(\"CT always = %s,\\nTF always = %s,\\n BOTH = %s\" % (ct_set.difference(tf_set), tf_set.difference(ct_set), tf_set.intersection(ct_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=1,ncols=2,figsize=(8,2), sharey=True)\n",
    "\n",
    "st_errors_df.query(\"phone_os == 'android' & quality > 0\").boxplot(ax = ax_array[0], column=[\"error\"], by=[\"quality\"], showfliers=False)\n",
    "ax_array[0].set_title('android')\n",
    "st_errors_df.query(\"phone_os == 'ios' & quality > 0\").boxplot(ax = ax_array[1], column=[\"error\"], by=[\"quality\"], showfliers=False)\n",
    "ax_array[1].set_title(\"ios\")\n",
    "\n",
    "for i, ax in enumerate(ax_array):\n",
    "    # print([t.get_text() for t in ax.get_xticklabels()])\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "ax_array[0].set_ylabel(\"Spatio-temporal error (meters)\")\n",
    "# ax_array[1][0].set_ylabel(\"Spatial error (meters)\")\n",
    "ifig.suptitle(\"Spatio-temporal trajectory error v/s quality (excluding outliers)\", y = 1.1)\n",
    "# ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=1,ncols=2,figsize=(8,2), sharey=True)\n",
    "\n",
    "st_errors_df.query(\"phone_os == 'android' & quality > 0\").boxplot(ax = ax_array[0], column=[\"error\"], by=[\"quality\"])\n",
    "ax_array[0].set_title('android')\n",
    "st_errors_df.query(\"phone_os == 'ios' & quality > 0\").boxplot(ax = ax_array[1], column=[\"error\"], by=[\"quality\"])\n",
    "ax_array[1].set_title(\"ios\")\n",
    "\n",
    "for i, ax in enumerate(ax_array):\n",
    "    # print([t.get_text() for t in ax.get_xticklabels()])\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "ax_array[0].set_ylabel(\"Spatial-temporal error\")\n",
    "# ax_array[1][0].set_ylabel(\"Spatial error (meters)\")\n",
    "ifig.suptitle(\"Spatio-temporal trajectory error v/s quality\", y = 1.1)\n",
    "# ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out results by timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=2,ncols=3,figsize=(12,6), sharex=False, sharey=False)\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\", \"car_scooter_brex_san_jose\", \"unimodal_trip_car_bike_mtv_la\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    st_errors_df.query(\"timeline == @tl & phone_os == 'android' & quality > 0\").boxplot(ax = ax_array[0][i], column=[\"error\"], by=[\"quality\"])\n",
    "    ax_array[0][i].set_title(tl)\n",
    "    st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & quality > 0\").boxplot(ax = ax_array[1][i], column=[\"error\"], by=[\"quality\"])\n",
    "    ax_array[1][i].set_title(\"\")\n",
    "\n",
    "for i, ax in enumerate(ax_array[0]):\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "for i, ax in enumerate(ax_array[1]):\n",
    "    ax.set_xticklabels([q2r_map[int(t.get_text())] for t in ax.get_xticklabels()])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "ax_array[0][0].set_ylabel(\"Spatio-temporal error (android)\")\n",
    "ax_array[1][0].set_ylabel(\"Spatio-temporal error (ios)\")\n",
    "ifig.suptitle(\"Spatio-temporal trajectory error v/s quality\")\n",
    "# ifig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out results by section for the most complex timeline (train_bus_ebike_mtv_ucb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ifig, ax_array = plt.subplots(nrows=2,ncols=4,figsize=(25,10), sharex=True, sharey=True)\n",
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    for q in range(1,5):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & quality == @q\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i][q-1], column=[\"error\"], by=[\"section_id\"])\n",
    "        ax_array[2*i][q-1].tick_params(axis=\"x\", labelrotation=45)\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & quality == @q\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i+1][q-1], column=[\"error\"], by=[\"section_id\"])\n",
    "#        ax_array[i][].set_title(\"\")\n",
    "\n",
    "def make_acronym(s):\n",
    "    ssl = s.split(\"_\")\n",
    "    # print(\"After splitting %s, we get %s\" % (s, ssl))\n",
    "    if len(ssl) == 0 or len(ssl[0]) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return \"\".join([ss[0] for ss in ssl])\n",
    "\n",
    "for q in range(1,5):\n",
    "    ax_array[0][q-1].set_title(q2r_map[q])\n",
    "    curr_ticks = [t.get_text() for t in ax_array[1][q-1].get_xticklabels()]\n",
    "    new_ticks = [make_acronym(t) for t in curr_ticks]\n",
    "    ax_array[1][q-1].set_xticklabels(new_ticks)\n",
    "    \n",
    "print(list(zip(curr_ticks, new_ticks)))\n",
    "# fig.text(0,0,\"%s\"% list(zip(curr_ticks, new_ticks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    unique_sections = st_errors_df.query(\"timeline == @tl\").section_id.unique()\n",
    "    ifig, ax_array = plt.subplots(nrows=2,ncols=len(unique_sections),figsize=(40,10), sharex=True, sharey=False)\n",
    "    for sid, s_name in enumerate(unique_sections):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i][sid].set_title(s_name)\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i+1][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i+1][sid].set_title(\"\")\n",
    "#        ax_array[i][].set_title(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus only on sections where the max error is > 1000 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timeline_list = [\"train_bus_ebike_mtv_ucb\"]\n",
    "for i, tl in enumerate(timeline_list):\n",
    "    unique_sections = pd.Series(st_errors_df.query(\"timeline == @tl\").section_id.unique())\n",
    "    sections_with_outliers_mask = unique_sections.apply(lambda s_name: st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb' & section_id == @s_name\").error.max() > 1000)\n",
    "    sections_with_outliers = unique_sections[sections_with_outliers_mask]   \n",
    "    ifig, ax_array = plt.subplots(nrows=2,ncols=len(sections_with_outliers),figsize=(20,4), sharex=True, sharey=False)\n",
    "    for sid, s_name in enumerate(sections_with_outliers):\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'android' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i][sid].set_title(s_name)\n",
    "        ax_array[2*i][sid].set_xlabel(\"\")\n",
    "        sel_df = st_errors_df.query(\"timeline == @tl & phone_os == 'ios' & section_id == @s_name & quality > 0\")\n",
    "        if len(sel_df) > 0:\n",
    "            sel_df.boxplot(ax = ax_array[2*i+1][sid], column=[\"error\"], by=[\"quality\"])\n",
    "        ax_array[2*i+1][sid].set_title(\"\")\n",
    "        print([t.get_text() for t in ax_array[2*i+1][sid].get_xticklabels()])\n",
    "        ax_array[2*i+1][sid].set_xticklabels([q2r_map[int(t.get_text())] for t in ax_array[2*i+1][sid].get_xticklabels() if len(t.get_text()) > 0])\n",
    "        ax_array[2*i+1][sid].set_xlabel(\"\")\n",
    "    ifig.suptitle(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (express bus iOS, MAHFDC)\n",
    "\n",
    "ok, so it looks like the error is non-trivial across all runs, but run #1 is the worst and is responsible for the majority of the outliers. And this is borne out by the map, where on run #1, we end up with points in San Leandro!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(emr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_leg_gj = ezgj.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/express_bus_1\"][\"reference_df\"], color=\"green\")\n",
    "curr_map = ezgj.get_map_for_geojson(gt_leg_gj, name=\"ground_truth\")\n",
    "ezgj.get_fg_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/express_bus_1\"][\"reference_df\"], name=\"gt_points\", color=\"green\").add_to(curr_map)\n",
    "\n",
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus' & run == 1\"))\n",
    "gt_16k = lambda lr: lr[\"error\"] == error_df.error.max()\n",
    "folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=\"red\"), name=\"sensed_values\").add_to(curr_map)\n",
    "ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points\", color=\"red\", popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_leg = sd_ucb.get_ground_truth_for_leg(\"berkeley_to_mtv_SF_express_bus\", \"express_bus\"); print(gt_leg[\"id\"])\n",
    "curr_map = ezgj.get_map_for_geojson(sd_ucb.get_geojson_for_leg(gt_leg), name=\"ground_truth\")\n",
    "ezgj.get_fg_for_loc_df(emd.linestring_to_geo_df(eisd.SpecDetails.get_shapes_for_leg(gt_leg)[\"route\"]),\n",
    "                       name=\"gt_points\", color=\"green\").add_to(curr_map)\n",
    "\n",
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "\n",
    "colors = [\"red\", \"yellow\", \"blue\"]\n",
    "for run in range(3):\n",
    "    error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'ios' & quality == 2 & section_id == 'express_bus' & run == @run\"))\n",
    "    gt_16k = lambda lr: lr[\"error\"] == error_df.error.max()\n",
    "    print(\"max error for run %d is %s\" % (run, error_df.error.max()))\n",
    "    folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=colors[run]), name=\"sensed_values\").add_to(curr_map)\n",
    "    ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points\", color=colors[run], popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (commuter rail aboveground android, HAMFDC)\n",
    "\n",
    "Runs along El Camino instead of the Caltrain tracks for a while. Not sure if this is even an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & quality == 1 & section_id == 'commuter_rail_aboveground' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-3\"][\"evaluation_ranges\"][0]; ucb_and_back[\"trip_id\"]\n",
    "to_trip = ucb_and_back[\"evaluation_trip_ranges\"][0]; print(to_trip[\"trip_id\"])\n",
    "train_leg = to_trip[\"evaluation_section_ranges\"][2]; print(train_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(to_trip[\"trip_id_base\"], train_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & quality == 1 & section_id == 'commuter_rail_aboveground' & error > 500\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_leg_gj = ezgj.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/commuter_rail_aboveground_0\"][\"reference_df\"], color=\"green\")\n",
    "curr_map = ezgj.get_map_for_geojson(gt_leg_gj, name=\"ground_truth\")\n",
    "ezgj.get_fg_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/commuter_rail_aboveground_0\"][\"reference_df\"], name=\"gt_points\", color=\"green\").add_to(curr_map)\n",
    "\n",
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'android' & quality == 1 & section_id == 'commuter_rail_aboveground' & run == 0\"))\n",
    "gt_16k = lambda lr: lr[\"error\"] == error_df.error.max()\n",
    "folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=\"red\"), name=\"sensed_values\").add_to(curr_map)\n",
    "ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points\", color=\"red\", popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sections = pd.Series(st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb'\").section_id.unique())\n",
    "sections_with_outliers_mask = unique_sections.apply(lambda s_name: st_errors_df.query(\"timeline == 'train_bus_ebike_mtv_ucb' & section_id == @s_name\").error.max() > 100)\n",
    "unique_sections[sections_with_outliers_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (walk_to_bus android, HAMFDC, HAHFDC)\n",
    "\n",
    "In the spatial-only accuracy, run 0 was the worst, with a zig-zag out to San Francisco. But the error magnitude was only ~ 3k since it wasn't that far from BART. Now that we account for temporal differences, the error is much larger (9k) but it is only a zig zag out to Ashby. I am guessing that the other error got stripped out because there was no matching timestamp. Not going to worry about that for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus' & error > 500\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus' & error > 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 1 | quality == 3) & section_id == 'walk_to_bus'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_ranges\"][1]; ucb_and_back[\"trip_id\"]\n",
    "to_trip = ucb_and_back[\"evaluation_trip_ranges\"][0]; print(to_trip[\"trip_id\"])\n",
    "wb_leg = to_trip[\"evaluation_section_ranges\"][6]; print(wb_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(to_trip[\"trip_id_base\"], wb_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gt_leg_gj = ezgj.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/walk_to_bus_0\"][\"reference_df\"], color=\"green\")\n",
    "curr_map = ezgj.get_map_for_geojson(gt_leg_gj, name=\"ground_truth\")\n",
    "ezgj.get_fg_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/walk_to_bus_0\"][\"reference_df\"], name=\"gt_points\", color=\"green\").add_to(curr_map)\n",
    "\n",
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'android' & quality == 3 & section_id == 'walk_to_bus' & run == 2\").sort_index(axis=\"index\"))\n",
    "gt_16k = lambda lr: lr[\"error\"] == error_df.error.max()\n",
    "folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=\"red\"), name=\"sensed_values\").add_to(curr_map)\n",
    "ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points\", color=\"red\", popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (light_rail_below_above_ground, android, accuracy_control)\n",
    "\n",
    "In this case, the spatial error was bad, but the temporal error is not that terrible, mainly because all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & quality == 4 & section_id == 'light_rail_below_above_ground' & error > 100\").run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#st_errors_df.query(\"phone_os == 'android' & (quality == 4) & section_id == 'light_rail_below_above_ground'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ucb_and_back = pv_ucb.map()[\"android\"][\"ucb-sdb-android-2\"][\"evaluation_ranges\"][2]; ucb_and_back[\"trip_id\"]\n",
    "back_trip = ucb_and_back[\"evaluation_trip_ranges\"][2]; print(back_trip[\"trip_id\"])\n",
    "lt_leg = back_trip[\"evaluation_section_ranges\"][7]; print(lt_leg[\"trip_id\"])\n",
    "gt_leg = sd_ucb.get_ground_truth_for_leg(back_trip[\"trip_id_base\"], lt_leg[\"trip_id_base\"]); gt_leg[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "curr_map = folium.Map()\n",
    "\n",
    "colors = [\"red\", \"yellow\", \"blue\"]\n",
    "for run in range(3):\n",
    "    gt_loc_df = ref_tree[\"train_bus_ebike_mtv_ucb\"][\"berkeley_to_mtv_SF_express_bus/light_rail_below_above_ground_%d\" % run][\"reference_df\"]\n",
    "    gt_leg = ezgj.get_geojson_for_loc_df(gt_loc_df, color=colors[i])\n",
    "    gt_feature = folium.GeoJson(gt_leg, name=\"ground_truth_%d\" % run).add_to(curr_map)\n",
    "    ezgj.get_fg_for_loc_df(gt_loc_df,\n",
    "                       name=\"gt_points_%d\" % run, color=\"light_%s\" % colors[i]).add_to(curr_map)\n",
    "    error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'android' & quality == 4 & section_id == 'light_rail_below_above_ground' & run == @run\"))\n",
    "    gt_16k = lambda lr: lr[\"error\"] == error_df.error.max()\n",
    "    print(\"max error for run %d is %s\" % (run, error_df.error.max()))\n",
    "    folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=colors[run]), name=\"sensed_values_%d\" % run).add_to(curr_map)\n",
    "    ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points_%d\" % run, color=colors[run], popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "\n",
    "curr_map.fit_bounds(gt_feature.get_bounds())\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (subway, android, HAMFDC)\n",
    "\n",
    "This is the poster child for temporal accuracy tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_leg_gj = ezgj.get_geojson_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/subway_underground_0\"][\"reference_df\"], color=\"green\")\n",
    "curr_map = ezgj.get_map_for_geojson(gt_leg_gj, name=\"ground_truth\")\n",
    "ezgj.get_fg_for_loc_df(ref_tree[\"train_bus_ebike_mtv_ucb\"][\"mtv_to_berkeley_sf_bart/subway_underground_0\"][\"reference_df\"], name=\"gt_points\", color=\"green\").add_to(curr_map)\n",
    "\n",
    "name_err_time = lambda lr: \"%d: %d, %s, %s\" % (lr[\"index\"], lr[\"df_idx\"], lr[\"error\"], sd_ucb.fmt(lr[\"ts\"], \"MM-DD HH:mm:ss\"))\n",
    "error_df = emd.to_loc_df(st_errors_df.query(\"phone_os == 'android' & quality == 1 & section_id == 'subway_underground' & run == 0\").sort_index(axis=\"index\"))\n",
    "maxes = [error_df.error.max(), error_df[error_df.index > 18].error.max()]\n",
    "gt_16k = lambda lr: lr[\"error\"] in maxes\n",
    "folium.GeoJson(ezgj.get_geojson_for_loc_df(error_df, color=\"red\"), name=\"sensed_values\").add_to(curr_map)\n",
    "ezgj.get_fg_for_loc_df(error_df, name=\"sensed_points\", color=\"red\", popupfn=name_err_time, stickyfn=gt_16k).add_to(curr_map)\n",
    "folium.LayerControl().add_to(curr_map)\n",
    "curr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    error_df.iloc[530:540],\n",
    "    error_df.iloc[675:685]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_errors_df.query(\"phone_os == 'android' & (quality == 4) & section_id == 'subway_underground'\").boxplot(column=\"error\", by=\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson as gj\n",
    "\n",
    "def display_gt_and_reference(entry, loc_df_label, with_points=False):\n",
    "    curr_map = folium.Map()\n",
    "    # print(\"Using ground truth %s\" % entry[\"ground_truth\"][\"leg\"][\"id\"])\n",
    "    gt_leg_gj = ezgj.get_geojson_for_linestring(entry[\"ground_truth\"][\"linestring\"], color=\"green\")\n",
    "    gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"ground_truth\")\n",
    "    curr_map.add_child(gt_leg_gj_feature)\n",
    "    if with_points:\n",
    "        gt_leg_gj_points = ezgj.get_point_markers(gt_leg_gj, name=\"ground_truth_points\", color=\"green\")\n",
    "        curr_map.add_child(gt_leg_gj_points)\n",
    "    \n",
    "    sensed_location_df = entry[loc_df_label]\n",
    "    # print(\"Adding section for %s with length %s\" % (loc_df_label, len(sensed_location_df)))\n",
    "    if len(sensed_location_df) > 0:\n",
    "        sensed_section_gj = gj.Feature(geometry=gj.LineString(coordinates=list(zip(sensed_location_df.longitude, sensed_location_df.latitude))),\n",
    "                                   properties={\"style\": {\"color\": \"red\"}, \"ts\": list(sensed_location_df.ts)})\n",
    "        sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"reference_trajectory\")\n",
    "        print(sensed_leg_gj_feature)\n",
    "        curr_map.add_child(sensed_leg_gj_feature)\n",
    "        if with_points:\n",
    "            sensed_leg_gj_points = ezgj.get_point_markers(sensed_section_gj, name=\"reference_points\", color=\"red\", tz=\"America/Los_Angeles\")\n",
    "            curr_map.add_child(sensed_leg_gj_points)\n",
    "    \n",
    "    curr_map.fit_bounds(gt_leg_gj_feature.get_bounds())\n",
    "    folium.LayerControl().add_to(curr_map)\n",
    "    return curr_map\n",
    "\n",
    "def add_section_and_points(curr_map, eval_section, loc_df_label, layer_name, disp_color, with_points=False):\n",
    "    sensed_location_df = eval_section[loc_df_label]\n",
    "    print(\"Adding section for %s with length %s\" % (layer_name, len(sensed_location_df)))\n",
    "    sensed_section_gj = gj.Feature(geometry=gj.LineString(coordinates=list(zip(sensed_location_df.longitude, sensed_location_df.latitude))),\n",
    "                                   properties={\"style\": {\"color\": disp_color}, \"ts\": list(sensed_location_df.ts)})\n",
    "    sensed_leg_gj_feature = folium.GeoJson(sensed_section_gj, name=\"sensed_values (%s)\" % layer_name)\n",
    "    curr_map.add_child(sensed_leg_gj_feature)\n",
    "    if with_points:\n",
    "        sensed_leg_gj_points = ezgj.get_point_markers(sensed_section_gj, name=\"sensed_points (%s)\" % layer_name,\n",
    "                                                      color=disp_color, tz=\"America/Los_Angeles\")\n",
    "        curr_map.add_child(sensed_leg_gj_points)\n",
    "\n",
    "def display_gt_and_controls(entry, loc_df_label, with_points=False):\n",
    "    curr_map = folium.Map()\n",
    "    print(\"Using ground truth %s\" % entry[\"ground_truth\"][\"leg\"][\"id\"])\n",
    "    gt_leg_gj = eisd.SpecDetails.get_geojson_for_leg(entry[\"ground_truth\"][\"leg\"])\n",
    "    gt_leg_gj_feature = folium.GeoJson(gt_leg_gj, name=\"ground_truth\")\n",
    "    curr_map.add_child(gt_leg_gj_feature)\n",
    "    if with_points:\n",
    "        gt_leg_gj_points = ezgj.get_point_markers(gt_leg_gj[2], name=\"ground_truth_points\", color=\"green\")\n",
    "        curr_map.add_child(gt_leg_gj_points)\n",
    "    \n",
    "    add_section_and_points(curr_map, entry[\"temporal_control\"][\"android\"], loc_df_label, \"android\", \"orange\", with_points)\n",
    "    add_section_and_points(curr_map, entry[\"temporal_control\"][\"ios\"], loc_df_label, \"ios\", \"purple\", with_points)\n",
    "    \n",
    "    curr_map.fit_bounds(gt_leg_gj_feature.get_bounds())\n",
    "    folium.LayerControl().add_to(curr_map)\n",
    "    return curr_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Considering entry suburb_bicycling suburb_bicycling 0\n",
    "##### max_gap for tf = 0.03349313290251375 > ct = 0.0008587982795516346 and density 0.7205317565438214 < 0.822728751810466, returning ct len = 958 not tf len = 839\n",
    "\n",
    "sel_name = \"suburb_city_driving_weekend/suburb_city_driving_weekend_3\"\n",
    "e = ref_tree[\"unimodal_trip_car_bike_mtv_la\"][sel_name]\n",
    "print(e[\"ground_truth\"].keys())\n",
    "display_gt_and_reference(e, \"reference_df\", with_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezgj.get_map_for_geojson(eisd.SpecDetails.get_geojson_for_leg(e[\"ground_truth\"][\"leg\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
